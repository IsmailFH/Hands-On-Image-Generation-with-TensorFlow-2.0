{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For some reasons, WGAN doesn't work well with this data. Don't spend too much time getting it to work, proceed to WGAN-GP notebook instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Tensorflow\", tf.__version__)\n",
    "\n",
    "from packaging.version import parse as parse_version\n",
    "assert parse_version(tf.__version__) < parse_version(\"2.4.0\"), \\\n",
    "    f\"Please install TensorFlow version 2.3.1 or older. Your current version is {tf.__version__}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_train, ds_info = tfds.load('fashion_mnist', split='train', shuffle_files=True, with_info=True)\n",
    "fig = tfds.show_examples(ds_info, ds_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_shape = (32, 32, 1)\n",
    "\n",
    "def preprocess(features):\n",
    "    image = tf.image.resize(features['image'], image_shape[:2])    \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image-127.5)/127.5\n",
    "    return image\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(preprocess)\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size, drop_remainder=True).repeat()\n",
    "\n",
    "train_num = ds_info.splits['train'].num_examples\n",
    "train_steps_per_epoch = round(train_num/batch_size)\n",
    "print(train_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class WGAN():\n",
    "    def __init__(self, input_shape):\n",
    "\n",
    "        self.z_dim = 128\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # losses\n",
    "        self.loss_critic_real = {}\n",
    "        self.loss_critic_fake = {}\n",
    "        self.loss_critic = {}\n",
    "        self.loss_generator = {}\n",
    "        \n",
    "        # critic\n",
    "        self.n_critic = 5\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        self.optimizer_critic = RMSprop(5e-5)\n",
    "\n",
    "        # build generator pipeline with frozen critic\n",
    "        self.generator = self.build_generator()\n",
    "        critic_output = self.critic(self.generator.output)\n",
    "        self.model = Model(self.generator.input, critic_output)\n",
    "        self.model.compile(loss = self.wasserstein_loss,\n",
    "                           optimizer =  RMSprop(5e-5))\n",
    "        self.critic.trainable = True\n",
    "\n",
    "        \n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "\n",
    "        w_loss = -tf.reduce_mean(y_true*y_pred)\n",
    "\n",
    "        return w_loss\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        DIM = 128\n",
    "        model = tf.keras.Sequential(name='Generator') \n",
    "\n",
    "        model.add(layers.Input(shape=[self.z_dim])) \n",
    "\n",
    "        model.add(layers.Dense(4*4*4*DIM))\n",
    "        model.add(layers.BatchNormalization()) \n",
    "        model.add(layers.ReLU())\n",
    "        model.add(layers.Reshape((4,4,4*DIM))) \n",
    "\n",
    "        model.add(layers.UpSampling2D((2,2), interpolation=\"bilinear\"))\n",
    "        model.add(layers.Conv2D(2*DIM, 5, padding='same')) \n",
    "        model.add(layers.BatchNormalization()) \n",
    "        model.add(layers.ReLU())\n",
    "\n",
    "        model.add(layers.UpSampling2D((2,2), interpolation=\"bilinear\"))\n",
    "        model.add(layers.Conv2D(DIM, 5, padding='same')) \n",
    "        model.add(layers.BatchNormalization()) \n",
    "        model.add(layers.ReLU())\n",
    "\n",
    "        model.add(layers.UpSampling2D((2,2), interpolation=\"bilinear\"))       \n",
    "        model.add(layers.Conv2D(image_shape[-1], 5, padding='same', activation='tanh')) \n",
    "\n",
    "        return model             \n",
    "    \n",
    "    def build_critic(self):\n",
    "\n",
    "        DIM = 128\n",
    "        model = tf.keras.Sequential(name='critics') \n",
    "\n",
    "        model.add(layers.Input(shape=self.input_shape)) \n",
    "\n",
    "        model.add(layers.Conv2D(1*DIM, 5, strides=2, padding='same'))\n",
    "        model.add(layers.LeakyReLU(0.2))\n",
    "\n",
    "        model.add(layers.Conv2D(2*DIM, 5, strides=2, padding='same'))\n",
    "        model.add(layers.BatchNormalization()) \n",
    "        model.add(layers.LeakyReLU(0.2))\n",
    "\n",
    "        model.add(layers.Conv2D(4*DIM, 5, strides=2, padding='same'))\n",
    "        model.add(layers.BatchNormalization()) \n",
    "        model.add(layers.LeakyReLU(0.2))\n",
    "\n",
    "\n",
    "        model.add(layers.Flatten()) \n",
    "        model.add(layers.Dense(1)) \n",
    "\n",
    "        return model     \n",
    "    \n",
    " \n",
    "    def train_critic(self, real_images, batch_size):\n",
    "\n",
    "        real_labels = tf.ones(batch_size)\n",
    "        fake_labels = -tf.ones(batch_size)\n",
    "                  \n",
    "        g_input = tf.random.normal((batch_size, self.z_dim))\n",
    "        fake_images = self.generator.predict(g_input)\n",
    "        \n",
    "        with tf.GradientTape() as total_tape:\n",
    "            \n",
    "            # forward pass\n",
    "            pred_fake = self.critic(fake_images)\n",
    "            pred_real = self.critic(real_images)\n",
    "            \n",
    "            # calculate losses\n",
    "            loss_fake = self.wasserstein_loss(fake_labels, pred_fake)\n",
    "            loss_real = self.wasserstein_loss(real_labels, pred_real)           \n",
    "\n",
    "            # total loss\n",
    "            total_loss = loss_fake + loss_real\n",
    "            \n",
    "            # apply gradients\n",
    "            gradients = total_tape.gradient(total_loss, self.critic.trainable_variables)\n",
    "            \n",
    "            self.optimizer_critic.apply_gradients(zip(gradients, self.critic.trainable_variables))\n",
    "\n",
    "        for layer in self.critic.layers: \n",
    "            weights = layer.get_weights() \n",
    "            weights = [tf.clip_by_value(w, -0.01, 0.01) for w in weights]\n",
    "            layer.set_weights(weights) \n",
    "\n",
    "        return loss_fake, loss_real\n",
    "                                                \n",
    "    def train(self, data_generator, batch_size, steps, interval=200):\n",
    "\n",
    "        val_g_input = tf.random.normal((batch_size, self.z_dim))\n",
    "        real_labels = tf.ones(batch_size)\n",
    "\n",
    "        for i in range(steps):\n",
    "            for _ in range(self.n_critic):\n",
    "                real_images = next(data_generator)\n",
    "                loss_fake, loss_real = self.train_critic(real_images, batch_size)\n",
    "                critic_loss = loss_fake + loss_real\n",
    "                \n",
    "            # train generator\n",
    "            g_input = tf.random.normal((batch_size, self.z_dim))\n",
    "            g_loss = self.model.train_on_batch(g_input, real_labels)\n",
    "            \n",
    "            self.loss_critic_real[i] = loss_real.numpy()\n",
    "            self.loss_critic_fake[i] = loss_fake.numpy()\n",
    "            self.loss_critic[i] = critic_loss.numpy()\n",
    "            self.loss_generator[i] = g_loss\n",
    "\n",
    "            if i%interval == 0:\n",
    "                msg = \"Step {}: g_loss {:.4f} critic_loss {:.4f} critic fake {:.4f}  critic_real {:.4f}\"\\\n",
    "                .format(i, g_loss, critic_loss, loss_fake, loss_real)\n",
    "                print(msg)\n",
    "\n",
    "                fake_images = self.generator.predict(val_g_input)\n",
    "                self.plot_images(fake_images)\n",
    "                self.plot_losses()\n",
    "\n",
    "    def plot_images(self, images):   \n",
    "        grid_row = 1\n",
    "        grid_col = 8\n",
    "        f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*2.5, grid_row*2.5))\n",
    "        for row in range(grid_row):\n",
    "            for col in range(grid_col):\n",
    "                if self.input_shape[-1]==1:\n",
    "                    axarr[col].imshow(images[col,:,:,0]*0.5+0.5, cmap='gray')\n",
    "                else:\n",
    "                    axarr[col].imshow(images[col]*0.5+0.5)\n",
    "                axarr[col].axis('off') \n",
    "        plt.show()\n",
    "\n",
    "    def plot_losses(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "        fig.set_figwidth(10)\n",
    "        fig.set_figheight(6)\n",
    "        ax1.plot(list(self.loss_critic.values()), label='Critic loss', alpha=0.7)\n",
    "        ax1.set_title(\"Critic loss\")\n",
    "        ax2.plot(list(self.loss_generator.values()), label='Generator loss', alpha=0.7)\n",
    "        ax2.set_title(\"Generator loss\")\n",
    "\n",
    "        plt.xlabel('Steps')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(image_shape)\n",
    "wgan.generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wgan.train(iter(ds_train), batch_size, 2000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = tf.random.normal((8, 128))\n",
    "generated_images = wgan.generator.predict(z)\n",
    "wgan.plot_images(generated_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.generator.save_weights('./models/wgan_fashion_mnist.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgentf2",
   "language": "python",
   "name": "imgentf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
